{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "racial-blair",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# GWAS: Regenie for single variant and rare variant (aggregate tests) analysis in a public data-set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-transformation",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Here we show how to run a genome wide association analysis (GWAS) using regenie with our `regenie.ipynb` pipeline using a public dataset from 1000 genomes. \n",
    "\n",
    "This tutorial has been created to be run on a single computer (a desktop, laptop, or a single interactive node on a cluster). The pipeline has been implemented in SoS workflow language and can be configured to run in parallel on a high performance computing cluster environment. Please read the [SoS documentation](https://vatlab.github.io/sos-docs/doc/user_guide/host_setup.html) on how to configure the software and workflow to efficiently perform the analysis for real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-parish",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Over the past few years, there have been many tools created to run GWAS with increasing number of samples and genetic variants. Aditionally, these softwares use linear mixed models (LMM) to account for population structure, sample relatedness and estimate the genetic architecture of complex traits. BoltLMM, FastGWA and [Regenie](https://rgcgithub.github.io/regenie/) are some of them. \n",
    "\n",
    "Regenie can perform GWAS's in very large datases such as the UK Biobank.\n",
    "\n",
    "## Regenie properties\n",
    "\n",
    "1. Works with quantitative and binary traits (case-control), including those with unbalanced samples case-control ratio. Supports Firth logistic regression and Saddle Point Approximation (SPA) for binary traits.\n",
    "2. Performs linear mixed models (LMM) for quantitative traits and generalized LMM (GLMM) for binary traits using an approximate method. Which allows for the inclusion of related individuals, without increasing type I errors. Even if there are known related indviduals there can be cryptic related individuals and thefore it is advantageous to use LMM/GLMM\n",
    "3. Offers the advantage of processing multiple phenotypes at the same time. However you should be aware that quantitave or binary traits need to be analyzed separately (phenotype information must be provided in separate files). Also, the proportion of missing data should be similar for all of the traits analyzed at once, since it can impact predictions. Authors of regenie recommend to analyze traits in groups that have similar missingness patterns with resonably low amount of missingness (<15%). Therefore for outcome phenotypes it is usually best to analyze them separately. \n",
    "4. It can handle different types of genetic data (microarray, imputed, exome sequencing) and formats (PLINK:bed/bim/fam, PLINK2:pgen/pvar/psam and BGEN).\n",
    "5. It is designed to handle a large number of samples ~500K. Regenie is not appropiate to analyze binary traits with very small samples sizes. Additionally, regenie can get conservative in more extreme relatedness scenarios it is recommended for smaller cohorts with high amounts of relatedness to use mixed-model methods. \n",
    "6. Integrates covariates into the model.\n",
    "\n",
    "## Method\n",
    "\n",
    "Regenie works in two different steps that are independent from each other. \n",
    "\n",
    "### Step 1. Fitting the null \n",
    "\n",
    "The first step is where it fits the null regression model, for this regenie uses a subset of genetic markers that capture a good proportion of the phenotype variance that is attributable to genetic effects. The ridge regression takes account of Linkage disequilibrium (LD) within each block, therefore prunning is not necessary. However, it is not recommended to use over 500,000 markers for this step. \n",
    "\n",
    "- Level 0: Ridge regression applied to block of SNPs to reduce dimensions\n",
    "- Level 1: Linear or logistic ridge regressions within cross validation scheme\n",
    "\n",
    "### Step 2. Association analysis\n",
    "\n",
    "All genetic markers of interest are used to test for association, using a linear or logistic (score test) regression, with the traits conditional upon the prediction from the regression model on step 1. This is done by using the Leave One Chromosome Out (LOCO) scheme to avoid proximal contamination. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-bulletin",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "In order to run this workflow you will need to have installed [docker](https://docs.docker.com/get-docker/) in you local computer previously, and have created an account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-richardson",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-female",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Genotype data\n",
    "\n",
    "For this exercise we will use data from 1000 genomes which was downloaded from the publicly available database [MAGMA](https://ctg.cncr.nl/software/magma).The number of individuals in this dataset is n=489.\n",
    "\n",
    "Please note that this is only an example dataset for real life applications a much larger sample size is necessary. We have generated principal components (PCs) for you to include in the analysis using FLASHPCA so that you can adjust for potential population substructure/admixture in the analysis. When appropriate, PCs should be included in the analysis even with a LMM/GLMM approximation is used.\n",
    "\n",
    "The genotype file has been pruned (variants in LD removed) to reduce the number of variants to make sure the excercise can be finished in a reasonable amount of time. When you analyze your data you would want to analyze all variants and not a prunned set. Prunning is often used to remove variants in LD to create a subset of variants for PC analysis for example. For reproducibility these are the commands that have been used for pruning. We used variants with a r2<0.01, window sizes of 100, and a shift of 10 variants.  Please note you **DO NOT** have to run this part of the exercise, since this has already been done in advance for you. If you would like more information about the pruning procedure you can read more about this in [plink](https://www.cog-genomics.org/plink/1.9/ld)\n",
    "\n",
    "\n",
    "```\n",
    "plink2 --bfile 1000G.EUR --indep-pairwise 100 10 0.01 --out 1000G.EUR.mwe\n",
    "plink2 --bfile 1000G.EUR --extract 1000G.EUR.mwe.prune.in --make-bed --out 1000G.EUR.mwe.pruned\n",
    "```\n",
    "This prunned genotype array file (`1000G.EUR.mwe.pruned.{bed,bim,fam}`) will be used for **Step 1** of Regenie\n",
    "\n",
    "```\n",
    "1000G.EUR.mwe.pruned.bed\n",
    "1000G.EUR.mwe.pruned.bim\n",
    "1000G.EUR.mwe.pruned.fam\n",
    "```\n",
    "\n",
    "The genotype file used for **Step 2** (`1000G.EUR.mwe.step2.regenie.qc.{bed,bim,fam}`)of regenie has been processed for quality control keeping variants and individuals with less than 10% missingness. Although in this step you would normally use all the markers you want to test for association with the phenotype, we are providing a smaller file since the original one downloaded from [MAGMA](https://ctg.cncr.nl/software/magma) contained over 22 million variants which will increase the computation time for this step. \n",
    "\n",
    "```\n",
    "plink2 --bfile 1000G.EUR.bed --indep-pairwise 100 10 0.5 --out 1000G.EUR.mwe.step2\n",
    "plink2 --bfile 1000G.EUR.bed --extract 1000G.EUR.mwe.step2.prune.in --make-bed --out 1000G.EUR.mwe.step2.regenie\n",
    "plink2 --bfile 1000G.EUR.mwe.step2.regenie --geno 0.1 --mind 0.1 --make-bed 1000G.EUR.mwe.step2.regenie.qc\n",
    "```\n",
    "\n",
    "## Phenotype file\n",
    "\n",
    "For the 1000G data there is not phenotype data available. Therefore we have created a phenotype `pheno` by randomly assigning study subjects as cases (1) or controls (0). We have also created the `sex` variable by randomly assigning individuals to male (0) or female (1). Therefore the data is generated under the null of no association. Please note that a plink file format is used therefore although we don't specify familial relationships these columns which contain 0s must be included. Please note that the phenotype file (1000G.EUR.pheno) is already given to you under the data folder. We have provided the code in case you are interested in understanding how we have generated this file. Additionally, we have calculated the first two principal components (PC1 and PC2) so that they can be added as covariates in Regenie.\n",
    "\n",
    "```\n",
    "# This script is made to be run with R\n",
    "## Load the library\n",
    "library(dplyr)\n",
    "## Read in the *.fam file for the 1000 genomes (Europeans)\n",
    "EUR_subset_fam <- read.table('1000G.EUR.mwe.pruned.fam',  head=F)\n",
    "## Give the table a header. This is the format in Plink fam files. In this case motherID and fatherID are both 0's in the dataset because we have unrelated individuals.\n",
    "colnames(EUR_subset_fam) <- c(\"FID\", \"IID\", \"motherID\", \"fatherID\", \"sex\", \"pheno\")\n",
    "# Create the phenotype variable pheno and randomly assign 0 for controls or 1 for cases\n",
    "EUR_subset_fam$pheno <- sample(c(0,1), replace=TRUE, size=489)\n",
    "# Create the sex variable and randomly assign 0 for males or 1 for females\n",
    "EUR_subset_fam$sex <- sample(c(0,1), replace=TRUE, size=489)\n",
    "# Create the phenotype file with the specific columns FID: family ID, IID: individual ID, sex and phenotype 'pheno'\n",
    "phenoFile <- EUR_subset_fam %>%\n",
    "    select('FID', \"IID\", \"sex\", \"pheno\")\n",
    "# Look at the data to make sure it's fine\n",
    "head(phenoFile)\n",
    "# Write to phenotype table to a tab separated file\n",
    "write.table(pheno,'1000G.EUR.pheno', sep=\"\\t\",row.names=F, quote=F)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-killing",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "## 1. Runing the single variant association analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-visit",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**1. Genotype file preparation and quality control (QC)**\n",
    "\n",
    "Before running regenie you need to make sure you have the files needed as input. \n",
    "Step 1 of Regenie only allows one genotype input file, so if for real life applications you have one plink binary file per chromosome you will need to merge them using plink. \n",
    "Quality control filters can be applied using Plink2 to filter out samples and markers in the genotype file prior to running Regenie's Step 1. \n",
    "\n",
    "In our example, we are going to carry out some quality control on the genotype data that is going to be used later to fit the null model of Regenie's Step 1 (ridge regression). \n",
    "\n",
    "The quality control process has been already integrated in the [regenie pipeline](https://github.com/cumc/bioworkflows/blob/master/GWAS/LMM.ipynb) under the `regenie_qc` step. \n",
    "\n",
    "For example, if we want to remove variants with minor allele frequency (MAF) lower that 5% we set the `maf_filter=0.05`, if we want to remove variants with over 10% of genotypes missing we set the parameter `geno_filter=0.1`, if we want to remove individuals with more than 10% of their genotypes missing we set the parameter `mind_filter=0.1` and lastly if we want to remove those variants exceding a p-value of 5e-08 for Hardy-Weinberg equilibrium we set the parameter `hwe_filter=5e-08`. \n",
    "\n",
    "Let the parameters for the initial quality control be:\n",
    "\n",
    "- maf_filter=0.05, we will remove variants with MAF <5%\n",
    "- geno_filter=0.1, we will remove variants with > 10% genotypes missing\n",
    "- mind_filter=0.1, we will remove individals with > 10% genotypes missing \n",
    "- hwe_filter=5e-08, we will remove variants exceeding a p-value for HWE > 5E-08\n",
    "\n",
    "The output produced in this part consist of two files:\n",
    "\n",
    "`1000G.EUR.mwe.pruned.qc_pass.id` and `1000G.EUR.mwe.pruned.snplist`, these contain the list of individuals and variants to keep in the Step 1 of Regenie. \n",
    "\n",
    "In this particular minimal working example (MWE) we keep n=102,497 variants for step 1 and n=489 samples that pass our QC filters. \n",
    "\n",
    "\n",
    "**2. Step 1: Fitting the null model**\n",
    "\n",
    "In this step, Regenie authors recommend to use the genotype array data (as opposed as imputed/exome data), as it provides better estimates of the phenotype variance. You also need to make sure that you don't have any Single Nucleotide Variants (SNVs) with a very low minor allele count (MAC), otherwise regenie will give an error message in the calculation of the stacked regressions.\n",
    "\n",
    "In our case, we will use the original genotype file in the parameter `bfile` and we will tell regenie which samples (`1000G.EUR.mwe.pruned.qc_pass.id`) and variants (`1000G.EUR.mwe.pruned.snplist`) to keep based on the results of our previous quality control. This part is actually integrated in our SoS pipeline, so it will automatically use the specified parameters for the `regenie_qc step` and `regenie_1`\n",
    "\n",
    "- bfile=1000G.EUR.mwe.pruned, we will use the pruned subset of the genotyped genetic markers to calculate the predictions.\n",
    "- block_size=1000 this will tell the program in how many \"chunks\" to divide the genotype file to make predictions\n",
    "\n",
    "The output produced in this step corresponds to: \n",
    "\n",
    "- A set of files (depending on the number of phenotypes analyzed) containing genomic predictions for each phenotype from Step 1 `1000G.EUR.pheno.regenie_1.loco`\n",
    "- A file called `1000G.EUR.pheno_x.regenie_pred.list` listing the locations of the prediction files\n",
    "\n",
    "**3. Step 2: Association analysis**\n",
    "\n",
    "In this step, namely step 2 of regenie, it will perform the single variant association analysis with each of the phenotypes. In real life scenarios you should test all the variants that have passed the quality control and not just the pruned subset. In our case, due to time contrains (we want the exercise to finish within the available time in the course) we will use a new genotype file after performing quality control (`--geno 0.1, --mind 0.1, and --hwe 5e-08`) to test for variant associations with the phenotype.\n",
    "\n",
    "Note: a convenient quality of Regenie is that step 1 and 2 are decoupled meaning that you can use all of the traits used in Step 1 or just a subset of them for the association analysis (Step 2). Also, you can test the association using array, exomed or imputed variants. This means that the `bfile` parameter ( the genotype data use to fit the null hypothesis) and the `genoFile` parameter (the genotype data use to test for association) can be different. \n",
    "\n",
    "For this example, we will use our phenotype x with the following parameters:\n",
    "\n",
    "- trait='bt' Here you define if your trait is binary (bt) or quantitative (leave empty). \n",
    "- covarCol=sex. In our particular case we will only use sex as covariate. However, if you have more than one qualitative covariate you can input them here separeted by comma\n",
    "- qCovarColList=PC1 PC2. In this case we will use the PC's as quantitative covariates.  \n",
    "- minMac=10 this flag is used to tell the program which minimum minor allele count (MAC) to use when testing variants, default value is 5. In real data applications you may want to set threshold depending on the power to detect associations based on your sample size. \n",
    "\n",
    "Additionally, we will use in the `--genoFile=1000G.EUR.mwe.step2.regenie.qc.bed` parameter the genotype file with the variants that we want to test for association. \n",
    "\n",
    "Regenie does not have a minMAF filter, so you would need to use the minMAC parameter and take into account the specific allele frequencies that you would like to test for to calculate the MAC based on your sample size. As an example, if you would like to test for variants with MAF=0.01 and you have 500 individuals then you would set a minMAC=50 (500 individuals * 2 alleles * 0.01 MAF)\n",
    "\n",
    "Depending on the type of data you are using, there are other useful parameters that you can explore. For example, with imputed data you may want to set the minimum info score to use (`--minINFO`), with quantitative phenotypes you may choose to use an inverse rank normalization (`--apply-rint`), for binary traits you can decide whether to use Firth (`--firth`) or Saddle Point Approximation (`--spa`) corrections. If you would like to explore any of Regenie's options please take a look at their [documentation](https://rgcgithub.github.io/regenie/options/)\n",
    "\n",
    "The output produced in this step corresponds to:\n",
    "\n",
    "- Summary statistics in a file with `*.regenie` extension, if option `-gz` was used this files will be compressed `*.regenie.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-fields",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### REGENIE: single variant association analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-forum",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now, we run the workflow `regenie` with the specific parameters. The SoS workflow consists of `regenie_1`: fitting the null, `regenie_2`: single variant association analysis, `regenie_3`: merge the association results into one file, `regenie_4`: generate the Manhattan and qq_plots. \n",
    "\n",
    "Note: when you execute the cell using (shift + enter), a star will appear on the left side inside the box. When the star dissapears it means that the run has finished. \n",
    "\n",
    "Please note that the `maf-filter`, `geno-filter`, `mind-filter` and `hwe-filter` are parameters needed for the `regenie_qc` step which is the quality control performed using Plink2 then that subsetted genotype file is used in to calculate the stacked regression of Regenie's Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad7f8b8-88d6-4d5b-93e3-132b7939218e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Command explanation\n",
    "\n",
    "The command in the following cell runs the regenie pipeline using a SoS workflow. A description of the commands is given below:\n",
    "\n",
    "* `cwd`:  the working directory where you would like your results to be stored\n",
    "* `bfile`: the genotype file to be used in the Step 1 of Regenie (to fit the null hypothesis). In our case `1000G.EUR.mwe.pruned.bed`\n",
    "* `maf-filter`: the minimum allele frequency to be used to filter the `bfile` (this is a parameter for plink2 and it's part of the quality control step of `regenie_qc`)\n",
    "* `geno-filter`: corresponds to the `-geno` option in plink, which removes all variants with missing call rates exceeding the provided value (this is a parameter for plink2 and is part of the QC step of `regenie_qc`)\n",
    "* `mind-filter`: corresponds to the `-mind` option in plink, which removes all samples with missing genotypes exceeding the provided value (this is a parameter for plink2 and it's part of the QC step of `regenie_qc`)\n",
    "* `hwe_filter`: corresponds to the `-hwe` option in plink, which filters out variants which have Hardy-Weinberg equilibrium exact test p-value below the provided threshold (this is a parameter for plink2 and it's part of the QC step of `regenie_qc`)\n",
    "* `genoFile`: corresponds to the file with the genetic data for association testing (Regenie Step 2). In this example `1000G.EUR.mwe.step2.regenie.qc.bed`\n",
    "* `phenoFile`: corresponds to the phenotype file which contains FID, IID, phenotypic information and covariates to be tested for association. In this example `1000G.EUR.pheno`\n",
    "* `formatFile`: a yml file to re-format the columns of the regenie summary statistics output\n",
    "* `phenoCol`: is the column of the phenoFile they contains the phenotype information. In example it is called `pheno`\n",
    "* `covarCol`: corresponds to the name of the covariates that should be included in the analysis. in this example `sex`\n",
    "* `qCovarCol`: corresponds to the name of the quantitative covariates that should be included in the analysis. In our case `PC1 PC2`\n",
    "* `chrList` :  the list of chromosomes to be analyzed in step 2 of regenie. In our case we will analyze chromosome 21 due to time constrains.\n",
    "* `numThreads`: is the number of computational threads to be used\n",
    "* `bsize`: is the size of genotype blocks to be used in Regenie Step 1 and 2\n",
    "* `trait`: the type of trait being analyzed in this case bt corresponds to a binary trait and if you leave empty this will indicate to regenie that it is a continous trait\n",
    "* `minMAC`: flag in regenie to specify the minimum minor allele count (MAC) when testing variants. In our case we can set it to `10`\n",
    "* `reverse_log_p`: is a specific parameter in the SoS regenie pipeline that we use to convert the $-log_{10}{ \\text{ p-value}}$ to p-value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-layout",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run regenie.ipynb regenie \\\n",
    "    --cwd output \\\n",
    "    --bfile 1000G.EUR.mwe.pruned.bed \\\n",
    "    --maf-filter 0.05 \\\n",
    "    --geno-filter 0.1 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe_filter 5e-08 \\\n",
    "    --genoFile 1000G.EUR.mwe.step2.regenie.qc.bed \\\n",
    "    --phenoFile 1000G.EUR.pheno\\\n",
    "    --formatFile regenie_template.yml \\\n",
    "    --phenoCol pheno \\\n",
    "    --covarCol sex \\\n",
    "    --qCovarCol PC1 PC2 \\\n",
    "    --chrList '21' \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 10 \\\n",
    "    --reverse_log_p "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-address",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now let's visualize the results of the association"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-semester",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Manhattan plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-subdivision",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png output/1000G.EUR_pheno.regenie.manhattan.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-patio",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-mineral",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png output/1000G.EUR_pheno.regenie.qq.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-kansas",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "**Question:** What is the inflation (lambda GC) value for this run? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-chest",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Lambda GC value\n",
    "\n",
    "You can get a general idea of the number or cases/controls, the number of variants analyzed and the lambda GC values by taking a look at the markdown file generated in the `output` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-noise",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat output/1000G.EUR_pheno.regenie.analysis_summary.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6a81d-8cce-4067-b54a-c8204f1702ff",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# Rare variant aggregate tests\n",
    "\n",
    "The advancement and availability of feasible sequencing technologies provide a rich opportunity to study the association between rare/low frequency variants and complex traits. \n",
    "Rare variants (minor allele frequencies (MAFs) of less than 0.01) might play an important role in the etiology of complex traits and account for missing heritability unexplained by common variants ([Bodmer W et.al 2008](https://pubmed.ncbi.nlm.nih.gov/18509313/), [Schork N.J et.al 2009](https://pubmed.ncbi.nlm.nih.gov/19481926/) and [Manolio TA et.al 2009](https://www.nature.com/articles/nature08494)).\n",
    "\n",
    "Gene-based or aggregate tests are recommended since individual rare variants have very low frequencies and limited statistical power when analyzed individually. Single-variant tests are typically conducted to investigate associations of common variants and phenotypes; however the same approach has little power when testing for rare-variant effects because of their low frequencies and the need of larger sample sizes. Instead, the statistical development of rare-variant analysis has been focused on testing cumulative effects of rare variants in genetic regions or SNP sets, such as genes. These tests can be broadly classified as burden and nonburden tests.\n",
    "\n",
    "In recent years, significant efforts have been devoted to developing powerful and computationally efficient statistical methods for testing associations between rare variants and complex traits. Here are some common gene-based association tests for rare variants:\n",
    "\n",
    "Instead of testing single variants for association with a phenotype, multiple variants can be aggregated within a region (e.g. gene) using the following model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323d6fe-e8ea-4385-8b17-b3c87563d9cc",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "$$g(\\mu) = w_1G_1\\beta_1\\, +\\, ... +\\, w_mG_m\\beta_m $$ \n",
    "\n",
    "where $G_i$'s represents the single variants included in the test, $w_i$'s and $\\beta_i$'s are are the weights and the effect sizes, respectively, for each variant and $g(.)$ is a link function for the phenotypic mean $\\mu$.\n",
    "\n",
    "In regenie the collapsing approach by SAIGE-GENE+ has been implemented to aggregate ultra rare variants into a mask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc9ff3-bcfd-4448-ad7a-2e779bb1e270",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "**1. Burden Tests**\n",
    "\n",
    "Burden tests, are fixed effect tests, that combine the effects of rare variants within a gene into a single test statistic. Different burden tests include the \"collapsing\" approach (combining individual variant p-values) and the \"summarized\" approach (summing variant effects within a gene). Because all burden tests implicitly assume that all the rare variants in a region are causal and affect the phenotype in the same direction with similar magnitudes, they suffer from a substantial loss of power when these assumptions are violated.\n",
    "References: [Leal SM et.al 2008](https://pubmed.ncbi.nlm.nih.gov/18691683/), [Browning S.R et.al 2009](https://pubmed.ncbi.nlm.nih.gov/19214210/), [Zeggini E et.al 2010](https://pubmed.ncbi.nlm.nih.gov/19810025/).\n",
    "\n",
    "In regenie the burden test is as defined in Lee et al 2014, which assumes $\\beta_i = \\beta \\, \\forall_i$, where $\\beta$ is a fixed coefficient and leads to the test statistic\n",
    "\n",
    "\n",
    "\n",
    "$$ Q_{burden} = \\left( \\sum_{i} \\, w_i S_i \\right)^2 $$\n",
    "\n",
    "This test collapses variants into one single variable that is then tested for association with the phenotype. There are multiple ways variants can be aggregate into masks explained in the section under `regenie: burden test`, however, the default way is to take the maximum number of rare alleles across all the variant sites within a region. The variants as shown in the formula above can also be weighted by allele frequencies or annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2be21-6045-436e-a340-bae0b4ee8a67",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "**2. Variance component tests**\n",
    "\n",
    "* **SKAT (Sequence Kernel Association Test)** [Lin X et.al 2011](https://pubmed.ncbi.nlm.nih.gov/21737059/)\n",
    " \n",
    "Instead of aggregating variants, SKAT aggregates individual variant-score test statistics with weights when SNV effects are modeled linearly. More generally, SKAT aggregates the associations between variants and the phenotype through a kernel matrix and can allow for SNV-SNV interactions, i.e., epistatic effects. SKAT is especially powerful when a genetic region has both protective and deleterious variants or many noncausal variants. It can be less powerful than burden tests if a large proportion of the rare variants in a region are truly causal and influence the phenotype in the same direction. In addition, large-sample-based p-value calculations, which SKAT uses, can produce conservative type I errors for small-sample case-control sequencing association studies, which could lead to a loss in power. \n",
    "\n",
    "SKAT assumes that effect sizes $\\beta_i$ come from an arbitrary distribution with mean 0 and variance $\\tau^2$, leading to the test statistic:\n",
    "\n",
    "\n",
    "$$ Q_{SKAT} =  \\sum_{i} \\, w_i^2 S_i^2  $$\n",
    "\n",
    "* **SKAT-O (Sequence Kernel Association Combined Test)** [Lin X et.al 2012](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3415556/)\n",
    "\n",
    "SKAT-O is an extension of SKAT that combines SKAT and the burden test. It allows for the flexibility of both kernel-based and collapsing approaches and provides a combined test statistic.\n",
    "\n",
    "  $$\n",
    "  Q_{\\text{SKATO}}=\\rho Q_{\\text{BURDEN}}+(1-\\rho)Q_{\\text{SKAT}}\n",
    "  $$\n",
    "\n",
    "\n",
    "Therefore, setting $\\rho=0$ corresponds to a SKAT test and $\\rho=1$ corresponds to a burden test. The parameter $\\rho$ is used to maximize power. Regenie uses a default grid of 8 values {${ 0.1^2,0.2^2, 0.3^2, 0.4^2, 0.5^2, 0.5,1}$} and sets the weight as $w_i= \\beta(MAF_i,1,25)$.\n",
    "\n",
    "Regenie allows for testing other types of aggregate tests such as SKATO-ACAT, ACATV, ACATO, and ACATO-FULL. Please refer to [regenie's tutorial](https://rgcgithub.github.io/regenie/overview/#step-2-gene-based-testing) for more details about these tests.\n",
    "\n",
    "# Packages/Software\n",
    "\n",
    "There are several R packages available to run gene-based association tests for rare variants that can be implemented in different programs like [REGENIE](https://rgcgithub.github.io/regenie/options/#skatacat-tests) and [GMMAT](https://cran.r-project.org/web/packages/GMMAT/vignettes/GMMAT.pdf)\n",
    "\n",
    "This particular gene-based analysis pipline is based on **REGENIE**. REGENIE can apply various set-based tests on the variants as well as collapse them into a single combined 'mask' genotype that can be tested for association just like a single (mega) variant. For example, the option `--vc-tests` is used to specify the SKAT and ACAT tests and the p-values for SKAT, SKATO, ACATV and ACATO will be outputted.\n",
    "For the details see the documentation here [REGENIE](https://rgcgithub.github.io/regenie/options/#skatacat-tests).\n",
    "\n",
    "**NOTE**: Proper data preprocessing, variant annotation, and quality control are essential steps before conducting rare-variant aggregate tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-bradford",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 2. Regenie : burden test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-celebrity",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Regenie offers the functionality of performing rare-variant aggregate association analysis. \n",
    "\n",
    "You can combine rare-variants in a gene or a region, using functional annotations to create masks that are then tested for association (as in a single variant analysis) with a phenotype. \n",
    "\n",
    "### Input files:\n",
    "\n",
    "1. You will need to provide an `annotation file` that is formatted: variant_id, gene/region, functional annotation (e.g. LoF, missense). You can use VEP or ANNOVAR to generate this information and then format it accordingly. \n",
    "2. Provide the `set-list-file`: this file contains a list of variants within each gene/region that's used when building the masks. The format is: gene/region name, chromosome, start_position, list of variants in the gene/region separated by comma. \n",
    "3. Optional: provide a file with genes/regions that you want to include or exclude from your analysis.\n",
    "4. Optional: provide an `allele-frequency` file to use when creating the masks. By default the allele frequency is computed from the sample. In our case we are providing an allele-frequency file, obtained from gnomAD exome frequencies. We will use the AF_nfe field which contains the allele frequencies from exome data for non Finnish Europeans available in gnomAD. \n",
    "5. Mask file: this is a text file that contains the name of the mask and the type of annotations to use when building it (one mask per line). E.g. \n",
    "\n",
    "```\n",
    "mask1 LoF,missense\n",
    "```\n",
    "\n",
    "6. You need to provide the `--aaf-bins` cut-off in the parameters. This refers to the AAF upper bounds to use when creating the masks. By default regenie_burden produces results for singletons and if you set `--aaf-bins` to be for example 0.01 it will create masks from  [0,0.01] and singletons. \n",
    "\n",
    "Additionally, you can choose the way the mask are built. These options are:\n",
    "- using the maximum number of ALT alleles across sites ('max'; the default)\n",
    "- using the sum of ALT alleles ('sum')\n",
    "- using a maximum threshold of 2 ('comphet')\n",
    "\n",
    "![Rules to build mask](https://rgcgithub.github.io/regenie/img/mask_rules.png)\n",
    "\n",
    "\n",
    "For this MWE we have already generated the annotation, the set list, the allele frequency and the mask files that are provided in the `data` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-individual",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### REGENIE: burden test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79700b-299b-49f0-9df2-d8ffeaec0a93",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Command explanation\n",
    "\n",
    "In addition to the commands there are some extra parameters that need to bet set for the burden tests:\n",
    "\n",
    "* `anno-file`: is the path to the annotation file, which is required by regenie to run the burden analysis. Please refer to [regenie tutorial](https://rgcgithub.github.io/regenie/options/#annotation-input-files) to learn more\n",
    "* `aaf_file`: is the path to the allele frequency file, which is required by regenie to run the burden analysis. Please refer to [regenie tutorial](https://rgcgithub.github.io/regenie/options/#annotation-input-files) to learn more\n",
    "* `set_list`: is the path to set list file, which is required by regenie to run the burden analysis. Please refer to [regenie tutorial](https://rgcgithub.github.io/regenie/options/#annotation-input-files) to learn more\n",
    "* `mask_file`: corresponds to the mask_file path. Please refer to [regenie tutorial](https://rgcgithub.github.io/regenie/options/#annotation-input-files) to learn more\n",
    "* `build_mask`: parameter indicates the way that the mask should be created (max, sum and comphet). Please refer to [regenie tutorial](https://rgcgithub.github.io/regenie/options/#annotation-input-files) to learn more \n",
    "* `aaf_bins`: refers to the alternative allele frequency (AAF) upper bounds to use when creating the masks. In this example `0.01` will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-variation",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run regenie.ipynb regenie_burden \\\n",
    "    --cwd output_burden \\\n",
    "    --bfile 1000G.EUR.mwe.pruned.bed \\\n",
    "    --maf-filter 0.01 \\\n",
    "    --geno-filter 0.1 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe_filter 5e-08 \\\n",
    "    --genoFile 1000G.EUR.mwe.step2.regenie.qc.bed \\\n",
    "    --phenoFile 1000G.EUR.pheno \\\n",
    "    --formatFile regenie_template.yml \\\n",
    "    --phenoCol pheno \\\n",
    "    --covarCol sex \\\n",
    "    --qCovarCol PC1 PC2 \\\n",
    "    --chrList '21' \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 1 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \\\n",
    "    --anno_file 1000G.EUR.hg19.hg19_multianno.csv.anno_file \\\n",
    "    --aaf_file 1000G.EUR.hg19.hg19_multianno.csv.aff_file \\\n",
    "    --set_list 1000G.EUR.hg19.hg19_multianno.csv.set_list_file\\\n",
    "    --mask_file 1000G.EUR.mask_file \\\n",
    "    --build_mask max \\\n",
    "    --aaf_bins  0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-wagner",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Output files\n",
    "\n",
    "After running regenie burden you will find the following output files in the `output_burden` folder:\n",
    "\n",
    "* `1000G.EUR.mwe.step2.regenie.qc_rarevariant_pheno.regenie.gz` This file contains the results only for mask1 and 0.01 bin\n",
    "* `1000G.EUR_pheno.regenie_burden.mask1.0.01.manhattan.png` Manhattan pot\n",
    "* `1000G.EUR_pheno.regenie_burden.mask1.0.01.qq.png` Q-Q plot\n",
    "* `1000G.EUR_pheno.regenie_burden.mask1.0.01.analysis_summary.md` Markdown file with summarized information\n",
    "\n",
    "Now let's visualize the results of the association. You can see that manhattan and q-q plots have been generated for mask1 with the 0.01 bin combination. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-catalyst",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Manhattan plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-craft",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%preview -s png output_burden/1000G.EUR_pheno.regenie_burden.mask1.0.01.manhattan.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-skirt",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-asthma",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png output_burden/1000G.EUR_pheno.regenie_burden.mask1.0.01.qq.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8964cfd-ad1d-4970-9da7-37b861e95637",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# 3. Regenie: SKAT-O test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9f9f4-99c1-4488-a63b-588534ce52bf",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "In regenie 3.0 new methods to perform rare variant aggregate tests have been added. More specifically, for a given set of variants (e.g. within a gene) which can be defined using functional annotations, regenie can apply various set-based tests:\n",
    "\n",
    "* SKAT: Variance component test\n",
    "* SKAT-O: Omnibus test combining features of SKAT and Burden\n",
    "* SKATO-ACAT: Same as SKATO but using Cauchy combination method to maximize power across SKATO models\n",
    "* ACATV:  Test using Cauchy combination method to combine single-variant p-values\n",
    "* ACATO: Omnibus test combining features of ACATV, SKAT and Burden\n",
    "* ACATO-FULL: Same as ACATO but using the larger set of SKATO models used in the SKATO test\n",
    "\n",
    "If you would like to include variants only under a given threshold allele frequency threshold (rare or ultrarare variants) you should define the parameter `--vc-maxAAF` or `--vc-MACthr` to set a MAC threshold under which all the variants will be considered in the analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d571e-6777-4118-8ce4-f7350b1b6214",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Command explanation\n",
    "\n",
    "In addition to the commands explained above, there are two more parameters that need to be set for the skat tests. \n",
    "\n",
    "* `vc_tests`: used to specify the gene-based tests to run (e.g skat, skato, acato, etc)\n",
    "* `vc_maxAAF`: is used to include variants whose alternative allele frequency (AAF) is below a given threshold\n",
    "* `vc_tests_reg`: is used during the manhattan and q-q plot generation, to indicate which plots you would like to generate depending on the tests run in regenie step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be705e79-4466-49a6-8ff1-74deb8f578d7",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run regenie.ipynb regenie_vc \\\n",
    "    --cwd output_vc \\\n",
    "    --bfile 1000G.EUR.mwe.pruned.bed \\\n",
    "    --maf-filter 0.01 \\\n",
    "    --geno-filter 0.1 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe_filter 5e-08 \\\n",
    "    --genoFile 1000G.EUR.mwe.step2.regenie.qc.bed \\\n",
    "    --phenoFile  1000G.EUR.pheno \\\n",
    "    --formatFile regenie_vc_template.yml \\\n",
    "    --phenoCol pheno \\\n",
    "    --covarCol sex \\\n",
    "    --qCovarCol PC1 PC2\\\n",
    "    --chrList '21' \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 1 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \\\n",
    "    --anno_file 1000G.EUR.hg19.hg19_multianno.csv.anno_file \\\n",
    "    --aaf_file 1000G.EUR.hg19.hg19_multianno.csv.aff_file \\\n",
    "    --set_list 1000G.EUR.hg19.hg19_multianno.csv.set_list_file \\\n",
    "    --mask_file 1000G.EUR.mask_file \\\n",
    "    --build_mask max\\\n",
    "    --vc_tests skato\\\n",
    "    --vc_tests_reg ADD-SKAT ADD-SKATO \\\n",
    "    --vc_maxAAF 0.01 \\\n",
    "    --aaf_bins  0.01 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2839651-2a0c-4ed5-a1fc-a4a995d6cb09",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Output files\n",
    "\n",
    "After running regenie skato you will find these relevant output files in the `output_vc` folder:\n",
    "\n",
    "- This file contains the merged results for skat, skato and also the additive univariate test for each variant\n",
    "`1000G.EUR_pheno.regenie_vc.snp_stats.gz`\n",
    "- This file contains only the results for the score test for SKAT\n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.snp_stats.gz`\n",
    "- This file contains only the results for the score test for SKATO\n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKATO.snp_stats.gz`\n",
    "- The manhattan plot for the SKATO\n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.manhattan.png`\n",
    "- The qq plot for the SKATO\n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.qq.png`\n",
    "- The summary of the analysis for the SKATO\n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKATO.analysis_summary.md`\n",
    "- The manhattan plot for the SKAT \n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.manhattan.png`\n",
    "- The qq plot for the SKAT\n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.qq.png`\n",
    "- The summary of the analysis for the SKAT\n",
    "`1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.analysis_summary.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92280894-369e-4cee-9412-5f39460ebc6b",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Manhattan and q-q plots for SKAT and SKAT-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebe5e7-a63d-4811-b130-599da0c710ad",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.manhattan.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28769a-7e28-43e4-9898-b9e92541d261",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.qq.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65449c36-fe51-4f2f-864d-a60f8a21f7ba",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat  output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.analysis_summary.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cbf08-9d1e-4208-bee6-3d3213a244cc",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKATO.manhattan.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bae86-0bf3-4c81-818c-61195bb36d4a",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKATO.qq.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223b8a3-358c-4141-8e85-3df53daf67cf",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKATO.analysis_summary.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8702e9-3281-4681-b5e0-db7b9a9d00ef",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "## Questions\n",
    "\n",
    "* How many genes did you analyze in each test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1dac6-ef02-4762-829d-f0db634c2e57",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "* What's the lambda GC for SKAT? and for SKAT-O?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ff608-04a7-4066-8092-a2682f6c5b3f",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "* What's the gene with the lowest p-value in SKAT and SKAT-O? Is it the same gene or a different one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971805de-5e03-4d07-bb30-e314428f25ff",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "* Why are there no significant tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04167e9f-cb32-4815-bc2c-0f37daaa68e1",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "**Additional exercise**\n",
    "\n",
    "Perform the analysis again but this time using chromosome 22.\n",
    "\n",
    "*Hint*: copy commands from above and change `chrList` to '22'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ea5e0-cd8a-4388-846f-61e20e269374",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb878444-bd34-44ce-8253-305a43813b91",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "* How many genes did you analyze in each test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baab8a7-75f8-4715-9d39-1c6f45f583eb",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "If you look into the markdown file you can see that the number of genes analyzed was 69 for both SKAT and SKAT-O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdebd2-52fd-41d0-9377-7feb4fbb7947",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "* What's the lambda GC for SKAT? and for SKAT-O?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125519b-4d06-4f1d-8ce2-3a44c098c646",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Again, by looking into the markdown file you can see that the lambda GC for SKAT is 0.648 and for SKAT-O it is 0.836"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff9e14-dc2d-498a-bdc2-ea2deafa1287",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "* What's the gene with the lowest p-value in SKAT and SKAT-O? Is it the same gene or a different one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8adb8b9a-fbc4-4c2b-b8cf-3b3016028767",
   "metadata": {
    "kernel": "Bash",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHR\tPOS\tREF\tALT\tSNP\tTEST\tCHISQ\tP\n",
      "21\t16332923\tref\tmask1.0.01\tNRIP1.mask1.0.01\tADD-SKAT\t3.83463\t0.05020419410211703\n",
      "21\t30299585\tref\tmask1.0.01\tLTN1.mask1.0.01\tADD-SKAT\t3.801\t0.051222409050966096\n",
      "21\t35735461\tref\tmask1.0.01\tKCNE2.mask1.0.01\tADD-SKAT\t3.4575\t0.0629651148701626\n",
      "21\t44312517\tref\tmask1.0.01\tNDUFV3.mask1.0.01\tADD-SKAT\t3.3204\t0.06842581832942414\n",
      "21\t42539293\tref\tmask1.0.01\tBACE2.mask1.0.01\tADD-SKAT\t3.25235\t0.07132142306525861\n",
      "21\t15856974\tref\tmask1.0.01\tSAMSN1.mask1.0.01\tADD-SKAT\t2.29389\t0.1298841031783759\n",
      "21\t45772638\tref\tmask1.0.01\tTRPM2.mask1.0.01\tADD-SKAT\t2.17825\t0.13997355731933953\n",
      "21\t30243656\tref\tmask1.0.01\tN6AMT1.mask1.0.01\tADD-SKAT\t1.93222\t0.164516325157312\n",
      "21\t47744127\tref\tmask1.0.01\tPCNT.mask1.0.01\tADD-SKAT\t1.86207\t0.17238560603476585\n"
     ]
    }
   ],
   "source": [
    "# You can take a look at the summary statistics to find the gene with the lowest p-value\n",
    "\n",
    "gzcat output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKAT.snp_stats.gz | sort -k8 -n | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd1ca2d8-487b-433b-92d8-bf2d0cd7b2ad",
   "metadata": {
    "kernel": "Bash",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHR\tPOS\tREF\tALT\tSNP\tTEST\tCHISQ\tP\n",
      "21\t16332923\tref\tmask1.0.01\tNRIP1.mask1.0.01\tADD-SKATO\t3.83463\t0.05020419410211703\n",
      "21\t30299585\tref\tmask1.0.01\tLTN1.mask1.0.01\tADD-SKATO\t3.801\t0.051222409050966096\n",
      "21\t35735461\tref\tmask1.0.01\tKCNE2.mask1.0.01\tADD-SKATO\t3.4575\t0.0629651148701626\n",
      "21\t44312517\tref\tmask1.0.01\tNDUFV3.mask1.0.01\tADD-SKATO\t3.3204\t0.06842581832942414\n",
      "21\t42539293\tref\tmask1.0.01\tBACE2.mask1.0.01\tADD-SKATO\t3.25235\t0.07132142306525861\n",
      "21\t15856974\tref\tmask1.0.01\tSAMSN1.mask1.0.01\tADD-SKATO\t2.29389\t0.1298841031783759\n",
      "21\t45772638\tref\tmask1.0.01\tTRPM2.mask1.0.01\tADD-SKATO\t2.17825\t0.13997355731933953\n",
      "21\t30243656\tref\tmask1.0.01\tN6AMT1.mask1.0.01\tADD-SKATO\t1.93222\t0.164516325157312\n",
      "21\t46032094\tref\tmask1.0.01\tKRTAP10-8.mask1.0.01\tADD-SKATO\t1.81868\t0.17747002071674153\n"
     ]
    }
   ],
   "source": [
    "gzcat output_vc/1000G.EUR_pheno.regenie_vc.mask1.0.01_ADD-SKATO.snp_stats.gz | sort -k8 -n | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e072455-3da8-4920-a77c-9d03d51d6b59",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "For SKAT the gene with the lowest p-value was NRIP1 which was borderline significant at the nominal value 0.05, and this is the same top hit for SKAT-O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61228590-3a78-47f7-9e73-e088eb8dc408",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "* Why are there no significant tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f57ac6c-22f4-4a9a-9aa1-8566c4c1e87f",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "The data for this exercise was derived under the null hypothesis so you don't expect any of the tests to be significant. However just by chance some of them could be significant and thus why in real life analyses the results need to be adjusted for multiple testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d690a15-d71b-49b7-9189-31fe1590ca7a",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
